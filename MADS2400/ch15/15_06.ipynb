{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.6 Case Study: Unsupervised Machine Learning, Part 1—Dimensionality Reduction \n",
    "* We’ve focused on **getting to know your data**\n",
    "* **Unsupervised machine learning** and **visualization** can help you **find patterns and relationships among unlabeled samples**\n",
    "* Visualizing data with **two variables** is easy\n",
    "    * Plot data in **2D** with **one variable along each axis**\n",
    "    * Visualization libraries also can plot datasets with **three variables in 3D** \n",
    "* But how do you visualize data with **more than three dimensions**?\n",
    "    * **Digits dataset** samples each have **64 features (dimensions) and a target value** \n",
    "    * **Big data** samples can have **hundreds**, **thousands** or even **millions of features (dimensions)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.6 Case Study: Unsupervised Machine Learning, Part 1—Dimensionality Reduction (cont.)\n",
    "* To **visualize**, must **reduce** the data to **two** or **three dimensions**\n",
    "* Use an **unsupervised machine learning** technique called **dimensionality reduction** \n",
    "* Visualizing the results can **reveal patterns in the data** that will help you **choose the most appropriate machine learning algorithms** to use\n",
    "* For example, **Clusters** of points might indicate **distinct classes** of information within the dataset\n",
    "\t* So a **classification algorithm** might be appropriate\n",
    "\t* Still need to **determine the class** of the samples in each cluster\n",
    "\t* Might require **consulting with a domain expert** and **studying samples in a cluster** to see **what they have in common** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.6 Case Study: Unsupervised Machine Learning, Part 1—Dimensionality Reduction (cont.)\n",
    "* **Dimensionality reduction** also serves other purposes\n",
    "    * **Training estimators on big data** with **significant numbers of dimensions** can take **hours, days, weeks or longer**. \n",
    "    * **Difficult for humans to think about highly dimensional data**\n",
    "    * Could eliminate or combine **closely correlated features** to **improve training performance** \n",
    "        * Might **reduce the accuracy** of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Digits Dataset\n",
    "* **Ignore Digits dataset labels** and use **dimensionality reduction** to help visualize the data in two dimensions\n",
    "* **We added `%matplotlib inline` to enable Matplotlib in this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `TSNE` Estimator for Dimensionality Reduction \n",
    "* `TSNE` estimator uses an algorithm called **t-distributed Stochastic Neighbor Embedding (t-SNE)** to analyze a dataset’s features and reduce them to the specified number of dimensions \n",
    "\t* [Algorithm’s details](https://scikit-learn.org/stable/modules/manifold.html#t-sne) are **beyond scope**\n",
    "\t* We first tried the popular **`PCA`** (principal components analysis) estimator but did not like the results, so we switched to **`TSNE`**\n",
    "* Create a `TSNE` object that **reduces a dataset’s features to two dimensions** \n",
    "* `random_state` for **reproducibility of the “render sequence”** when we display the digit clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the Digits Dataset’s Features into Two Dimensions\n",
    "* **Note: Takes about 15-20 seconds, so run code first**\n",
    "* Two steps\n",
    "\t* **Train the estimator** with the dataset\n",
    "\t* **Use the estimator** to **transform** the data into the **specified number of dimensions**\n",
    "* Can **perform separately** with `TSNE` methods **`fit`** and **`transform`**\n",
    "* Perform in **one statement** using **`fit_transform`**\n",
    "    * Returns array with **same number of rows** as `digits.data` and **two columns** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = tsne.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Reduced Data\n",
    "* Rather than Seaborn’s `scatterplot` function, use Matplotlib’s **`scatter` function**\n",
    "    * Returns collection of plotted items, which we’ll use in a second scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "dots = plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Black and white Digits dataset clustering scatterplot after TSNE dimensionality reduction to two dimensions](./ch14images/digits_black.png \"Black and white Digits dataset clustering scatterplot after TSNE dimensionality reduction to two dimensions\") -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Reduced Data (cont.)\n",
    "* **Did not label axes** &mdash; they **do not correspond to specific features** of the original dataset\n",
    "* **New features** produced by **`TSNE`** could be quite different from **dataset’s original features**\n",
    "* Clear **clusters** of related data points\n",
    "* Appear to be **11 main clusters, rather than 10** \n",
    "* Some **\"loose\" data points**  \n",
    "    * Makes sense because, as you saw, **some digits were difficult to classify**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Reduced Data with Different Colors for Each Digit\n",
    "* **Don’t know** whether all the **items in each cluster** represent the **same digit** \n",
    "    * If not, then the clusters are not helpful \n",
    "* Use **`target`s** in **Digits dataset** to **color the dots** to see whether clusters indeed represent specific digits\n",
    "* **`c=digits.target`** &mdash; use `target` values determine dot colors\n",
    "* **`cmap=plt.cm.get_cmap('nipy_spectral_r', 10)`** &mdash; **color map** to use \n",
    "    * Specifically use **10 distinct colors** for the 10 digits \n",
    "* Last statement adds color bar key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6, 5))\n",
    "\n",
    "dots = plt.scatter(reduced_data[:, 0], reduced_data[:, 1],\n",
    "    c=digits.target, cmap=plt.cm.get_cmap('nipy_spectral_r', 10))\n",
    " \n",
    "colorbar = plt.colorbar(dots)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (15.5): Using TSNE to Visualize the Digits Dataset in 3D\n",
    "* For interactivity: use `%matplotlib notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 15 of the book **Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**.\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
