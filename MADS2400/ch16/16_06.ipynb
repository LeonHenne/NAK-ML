{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.6 Convolutional Neural Networks for Vision; Multi-Classification with the MNIST Dataset \n",
    "* **`MNIST` database of handwritten digits**\n",
    "    * “The MNIST Database.” MNIST Handwritten Digit Database, Yann LeCun, Corinna Cortes and Chris Burges. http://yann.lecun.com/exdb/mnist/.\n",
    "* Create a [**convolutional neural network**](https://en.wikipedia.org/wiki/Convolutional_neural_network) (also called a **convnet** or **CNN**)\n",
    "* Common in **computer-vision applications**\n",
    "    * Recognizing handwritten digits and characters\n",
    "    * Recognizing objects in images and video\n",
    "    * Self-driving cars\n",
    "* **Non-vision applications**\n",
    "    * natural-language processing \n",
    "    * recommender systems\n",
    "    * much more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.6 Convolutional Neural Networks for Vision; Multi-Classification with the MNIST Dataset (cont.)\n",
    "* **60,000** labeled digit image samples for **training**, **10,000** for testing\n",
    "* **28-by-28 pixel images** (**784 features**), represented as **NumPy arrays**\n",
    "* **Grayscale pixel intensity** (shade) values **0-255** \n",
    "* **Convnet** will perform [**probabilistic classification**](https://en.wikipedia.org/wiki/Probabilistic_classification)\n",
    "\t* Model will output **10 probabilities** indicating likelihood a digit is **0-9**\n",
    "\t* **Highest probability** is the **predicted value**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility in Keras and Deep Learning\n",
    "* **Reproducibility is difficult** because the libraries **heavily parallelize floating-point calculations** \n",
    "* Each time calculations execute, they may execute in a **different order**\n",
    "* Can produce **different results** in each execution\n",
    "* See the [**Keras FAQ on reproducibility**](https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Keras Neural Network \n",
    "* **Network** (also called a **model**)\n",
    "    * Sequence of layers containing the neurons used to learn from the samples\n",
    "    * Each layer’s neurons receive inputs, process them (via an **activation function**) and produce outputs\n",
    "    * The more layers you **stack**, the **deeper** the network is, hence the term **deep learning**\n",
    "* **Loss function**\n",
    "    * Produces a measure of **how well the network predicts target values** \n",
    "    * **Lower loss values** indicate **better predictions**\n",
    "* **Optimizer**\n",
    "    * Attempts to **minimize the values produced by the loss function** to **tune the network** to make better predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.6.1 Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`load_data` function** loads **training** and **testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.6.2 Data Exploration\n",
    "* Check dimensions of the **training set images (`X_train`)**, **training set labels (`y_train`)**, **testing set images (`X_test`)** and **testing set labels (`y_test`)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Digits\n",
    "* Display 24 MNIST training set images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Digits\n",
    "* Run cell several times to view different digits and see **why handwritten digit recognition is a challenge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "index = np.random.choice(np.arange(len(X_train)), 24, replace=False)  # 24 indices\n",
    "figure, axes = plt.subplots(nrows=4, ncols=6, figsize=(16, 9))\n",
    "\n",
    "for item in zip(axes.ravel(), X_train[index], y_train[index]):\n",
    "    axes, image, target = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_xticks([])  # remove x-axis tick marks\n",
    "    axes.set_yticks([])  # remove y-axis tick marks\n",
    "    axes.set_title(target)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.6.3 Data Preparation\n",
    "* **Scikit-learn’s bundled datasets** were **preprocessed** into the **shapes its models required**\n",
    "* MNIST dataset **requires some preparation** for use in a Keras convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Image Data \n",
    "* **Keras convnets** require **NumPy array inputs** \n",
    "* Each **sample** must have the **shape**\n",
    "> `(`**width**`,` **height**`,` **channels**`)`\n",
    "* Each pixel has **one channel** (grayscale shade 0-255), so sample shapes will be \n",
    "> **`(28, 28, 1)`**\n",
    "* As the **neural network learns** from the images, it **creates many more channels**\n",
    "    * These channels will **represent more complex features**, like **edges**, **curves** and **lines**\n",
    "    * Enable network to **recognize digits** based on these features and how they’re **combined**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Image Data (cont.)\n",
    "* NumPy array method `reshape` receives a tuple representing the new shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((60000, 28, 28, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Image Data \n",
    "* **Numeric feature values** may vary widely\n",
    "* Deep learning networks **perform better** on data that's **normalized** into\n",
    "    * the range **0.0-1.0**, or \n",
    "    * a range for which the data’s **mean is 0.0** and its **standard deviation is 1.0**\n",
    "        * S. Ioffe and Szegedy, C., “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.” https://arxiv.org/abs/1502.03167\n",
    "* Divide **each pixel** value by **255** to normalize into the range **0.0-1.0**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding: Convert Labels to Categorical Data \n",
    "* **Predictions** for each digit will be an **array of 10 probabilities** \n",
    "* To **evaluate model accuracy**, Keras **compares predictions to dataset's labels**\n",
    "    * Both must have the **same shape**\n",
    "    * MNIST labels are **individual integers 0-9**\n",
    "* Must **transform labels** into **categorical data arrays** matching the **prediction format**\n",
    "* Use [**one-hot encoding**](https://en.wikipedia.org/wiki/One-hot) to convert labels from integers into 10-element **arrays of 1.0s and 0.0s** \n",
    "    * **only one element is 1.0** and the **rest are 0.0s**\n",
    "* Categorical representation of a **7**\n",
    "> <pre>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, <strong>1.0</strong>, 0.0, 0.0]</pre>\n",
    "* **`tensorflow.keras.utils`** function **`to_categorical`** performs **one-hot encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding: Convert Labels to Categorical Data (cont.)\n",
    "* Transform **`y_train`** and **`y_test`** into **two-dimensional arrays of categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]  # one sample’s categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.6.4 Creating the Neural Network\n",
    "* Configure a **convolutional neural network**\n",
    "* **`Sequential` model** stacks layers to **execute sequentially**\n",
    "    * **output** of one layer becomes **input** to the next\n",
    "    * **Feed-forward network**\n",
    "    * Later, you’ll see that not all layers feed output to the next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Layers to the Network\n",
    "* A typical **convnet** consists of \n",
    "\t* **input layer** that receives **training samples**\n",
    "\t* **hidden layers** that **learn** from training samples\n",
    "\t* **output layer** that **produces predictions**\n",
    "* Import layer classes for a basic **convnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (1 of 6)\n",
    "* We'll start with a **convolution layer**\n",
    "* Uses the **relationships between pixels in close proximity** to learn useful **features** (or patterns) in small areas of each sample\n",
    "* These **features** become **inputs** to **subsequent layers** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (cont.)\n",
    "* Examine convolution on a 6-by-6 image\n",
    "* **3-by-3 shaded square** represents the **kernel**\n",
    "* **Convolution** performs calculations that **learn** from kernel's **9** features, then **outputs 1 new feature** \n",
    "![Convolution diagram in which the 3-by-3 shaded square represents the kernel in its initial position](./ch16images/convolution.png \"Convolution diagram in which the 3-by-3 shaded square represents the kernel in its initial position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (cont.)\n",
    "* [**Kernels typically are 3-by-3**](https://www.quora.com/How-can-I-decide-the-kernel-size-output-maps-and-layers-of-CNN)\n",
    "    * We found convnets that used **5-by-5** and **7-by-7** \n",
    "    * Kernel-size is a **hyperparameter**\n",
    "* By looking at **features near one another**, the network begins to **recognize features** \n",
    "    * Like **edges**, **straight lines** and **curves**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (cont.)\n",
    "* Next, **convolution layer** moves **kernel one pixel to the right** (the **stride**) \n",
    "* **Overlaps** with previous kernel, so **convolution layer can learn** from all **features that touch one another**\n",
    "![Convolution diagram in which the 3-by-3 shaded square is moved one pixel to the right, overlapping with  of the three columns in the previous position](./ch16images/convolution2.png \"Convolution diagram in which the 3-by-3 shaded square is moved one pixel to the right, overlapping with  of the three columns in the previous position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (cont.)\n",
    "* **Complete pass** left-to-right and top-to-bottom is called a **filter**\n",
    "* For a **3-by-3 kernel**, the filter dimensions will be **two less than the input dimensions**\n",
    "    * For each 28-by-28 MNIST image, the filter will be 26-by-26 \n",
    "* **Number of filters** in the **convolutional layer** is commonly **32** or **64** for small images\n",
    "* Each filter produces different results\n",
    "* **Higher-resolution images** have **more features**, so they **require more filters**\n",
    "* **Keras team’s pretrained convnets** use 64, 128 or even 256 filters in their **first convolutional layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution (cont.)\n",
    "* **Set of filters** produced by a **convolution layer** is called a **feature map**\n",
    "* Subsequent **convolution layers** combine features from previous feature maps to **recognize larger features** and so on\n",
    "\t* In **facial recognition**, **early layers** might recognize **lines**, **edges** and **curves**, and **subsequent layers** might **combine** those into **features** like **eyes**, **eyebrows**, **noses**, **ears** and **mouths**\n",
    "* After **learning a feature**, a network can **recognize that feature anywhere** in the **image**\n",
    "    * One reason **convnets** are popular for **object recognition** in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Convolution Layer\n",
    "* **`Conv2D`** implements the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', \n",
    "               input_shape=(28, 28, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`filters=64`**—The number of **filters** in the resulting **feature map**.\n",
    "* **`kernel_size=(3, 3)`**—The **size of the kernel** used in each **filter**\n",
    "* **`activation='relu'`**—**Rectified Linear Unit activation function** is used to produce this layer’s output\n",
    "    * **Most widely used activation function** (Chollet, François. _Deep Learning with Python_. p. 72. Shelter Island, NY: Manning Publications, 2018)\n",
    "    * [**Good for performance** because it’s **easy to calculate**](https://towardsdatascience.com/exploring-activation-functions-for-neural-networks-73498da59b02) \n",
    "    * [Commonly recommended for **convolutional layers**](https://www.quora.com/How-should-I-choose-a-proper-activation-function-for-the-neural-network) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Convolution Layer (cont.)\n",
    "* **First layer** in the model, so we specify the shape of each sample with `input_shape=(28, 28,1)` \n",
    "\t* Creates an **input layer** to **load the samples** and pass them into the **`Conv2D` layer**, which is actually the **first hidden layer**\n",
    "* Each subsequent layer **infers `input_shape`** from previous layer’s **output shape**\n",
    "    * Makes it easy to **stack** layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality of the First Convolution Layer’s Output\n",
    "* Input samples are 28-by-28-by-1—that is, **784 features each**\n",
    "* Specified **64 filters** and a **3-by-3 kernel** for the layer, so the **feature map size is 26-by-26-by-64** for a total of **43,264 features** \n",
    "\t* **Significant increase in dimensionality** \n",
    "    * **Enormous** compared to numbers of features processed in our Machine Learning examples\n",
    "* As each layer adds features, feature map **dimensionality** grows significantly\n",
    "    * This is one of reason **deep learning** often requires **tremendous processing power**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting \n",
    "* Can occur when a **model is too complex** compared to what it is modeling\n",
    "* **Most extreme case**: Model **memorizes** its training data's features\n",
    "* **Overfitting** tends to occur in **deep learning** as the **dimensionality** becomes **too large** [\\[1\\]](https://cs231n.github.io/convolutional-networks/),[\\[2\\]](https://medium.com/@cxu24/why-dimensionality-reduction-is-important-dd60b5611543),[\\[3\\]](https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a)\n",
    "* **Higher dimensionality** also increases (and sometimes explodes) **computation time**\n",
    "* For deep learning on **CPUs**, training could become **intolerably slow**\n",
    "* There are various techniques to **prevent overfitting** [\\[1\\]](https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d), [\\[2\\]](https://www.kdnuggets.com/2015/04/preventing-overfitting-neural-networks.html) &mdash; we'll use **pooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Pooling Layer \n",
    "* To **reduce overfitting** and **computation time**, a **convolution layer** is often followed by one or more layers that **reduce dimensionality** of **convolution layer’s output**\n",
    "* **Pooling compresses** (or **down-samples**) the results by **discarding features**\n",
    "    * Helps make the model **more general**\n",
    "* **Most common pooling technique** is called **max pooling**\n",
    "\t* Examines a 2-by-2 square of features and keeps only the maximum feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Pooling Layer (cont.)\n",
    "* 2-by-2 blue square in position 1 represents the initial pool of features to examine:\n",
    "\n",
    "![Max pooling diagram showing the 6-by-6 set of numeric values we wish to compress with the 2-by-2 blue square in position 1 representing the initial pool of features to examine, and the 3-by-3 square representing the results of max pooling](./ch16images/pooling.png \"Max pooling diagram showing the 6-by-6 set of numeric values we wish to compress with the 2-by-2 blue square in position 1 representing the initial pool of features to examine, and the 3-by-3 square representing the results of max pooling\")z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Pooling Layer (cont.)\n",
    "* Outputs **maximum feature** from each pool\n",
    "* **Pools do not overlap** \n",
    "* **Stride** for a 2-by-2 pool is **2**\n",
    "* Every group of four features is reduced to one, so 2-by-2 pooling **compresses** number of features by **75%**\n",
    "* Reduces previous layer’s output from **26-by-26-by-64** to **13-by-13-by-64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Another Convolutional Layer and Pooling Layer\n",
    "* **Convnets** often have **many convolution and pooling layers**. \n",
    "* Keras team’s convnets tend to **double** the number of **filters** in subsequent **convolutional layers** to enable the models to learn more relationships between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Input** to the **second convolution layer** is the 13-by-13-by-64 **output of the first pooling layer**\n",
    "* **Output** of this **Conv2D layer** will be **11-by-11-by-128**\n",
    "* For **odd dimensions** like 11-by-11, **Keras pooling layers round down** by default (in this case to 10-by-10), so this pooling layer’s **output** will be **5-by-5-by-128**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening the Results\n",
    "* Model's **final output** will be a **one-dimensional** array of 10 probabilities that classify the digits\n",
    "* To prepare for **one-dimensional final predictions**, need to **flatten** the previous layer’s output to **one dimension**\n",
    "* **`Flatten`** layer's output will be **1-by-3200** (5 &#215; 5 &#215; 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Dense Layer to Reduce the Number of Features\n",
    "* Layers before the **`Flatten`** layer **learned digit features**\n",
    "* Now must **learn the relationships among those features** to **classify** which digit each image represents\n",
    "* Accomplished with **fully connected `Dense` layers**\n",
    "* The following **`Dense` layer** creates **128 neurons (`units`)** that **learn** from the 3200 outputs of the previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many **convnets** contain **at least one `Dense` layer** \n",
    "* **Convnets** geared to more complex image datasets with higher-resolution images like [**ImageNet**](http://www.image-net.org)—a dataset of over 14 million images—often have **several `Dense` layers**, commonly with **4096 neurons**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Another Dense Layer to Produce the Final Output\n",
    "* Final **`Dense`** layer **classifies** inputs into **neurons** representing the classes **0-9**\n",
    "* The **`softmax` activation function** converts values of these 10 neurons into **classification probabilities**\n",
    "* **Neuron** with **highest probability** represents the **prediction** for a given digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the Model’s Summary \n",
    "* Use model’s **`summary`** method\n",
    "* Note layers' **output shapes** and **numbers of parameters**\n",
    "* **Parameters** are the **weights** that the network **learns** during training [\\[1\\]](https://hackernoon.com/everything-you-need-to-know-about-neural-networks-8988c3ee4491),[\\[2\\]](https://www.kdnuggets.com/2018/06/deep-learning-best-practices-weight-initialization.html) \n",
    "* **Relatively small network**, but needs to **learn nearly 500,000 parameters**! \n",
    "\t* This is for **tiny images** that are less than 1/4 the size of icons on smartphone home screens\n",
    "\t* Imagine how many features a network would have to learn to process high-resolution 4K video frames or the super-high-resolution images produced by today’s digital cameras \n",
    "* In the **`Output Shape`** column, **`None`** means the model does not know in advance how many training samples you’re going to provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Model’s Structure \n",
    "* Use the **`plot_model` function** from module `tensorflow.keras.utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "plot_model(cnn, to_file='convnet.png', show_shapes=True, \n",
    "           show_layer_names=True)\n",
    "Image(filename='convnet.png')  # display resulting image in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model \n",
    "* Complete the model by calling its **`compile` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model (cont.)\n",
    "* **`optimizer='adam'`**—The **optimizer** this model uses to **adjust the weights** throughout the neural network **as it learns**\n",
    "\t* [**Keras optimizers**](https://keras.io/optimizers/)\n",
    "\t* `'adam'` performs well across a wide variety of models [\\[1\\]](https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2),[\\[2\\]](https://medium.com/nerd-for-tech/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-descent-1e32cdcbcf6c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model (cont.)\n",
    "* **`loss='categorical_crossentropy'`**—The **loss function** used by the optimizer in **multi-classification networks** (ours predicts 10 classes)\n",
    "\t* **Optimizer** attempts to **minimize the values returned by the loss function** \n",
    "\t* For **binary classification**, Keras provides **`'binary_crossentropy'`**, and for **regression**, **`'mean_squared_error'`**\n",
    "\t* [Other loss functions](https://keras.io/losses/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model (cont.)\n",
    "* **`metrics=['accuracy']`**—List of **metrics** the network will produce to help you **evaluate the model**\n",
    "\t* **Accuracy** commonly used in **classification models**\n",
    "\t* We’ll use it to check **percentage of correct predictions**\n",
    "\t* [Other metrics](https://keras.io/metrics/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.6.5 Training and Evaluating the Model \n",
    "* **Train a Keras model** by calling its **`fit` method**\n",
    "```python\n",
    "cnn.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
    "```\n",
    "* **`epochs=5`**&mdash;train neural networks iteratively over time\n",
    "    * Each **`epoch`** processes **every training dataset sample** once\n",
    "    * **Hyperparameter** that may need tuning\n",
    "* **`batch_size=64`**&mdash;**number of samples to process at a time**\n",
    "    * Most models specify a **power of 2 from 32 to 512**\n",
    "* [**`validation_split=0.1`**&mdash;model should reserve the **last** 10% of the training samples for validation](https://keras.io/getting-started/faq/#how-is-the-validation-split-computed) \n",
    "\t* After each **epoch**, model uses validation samples to **make predictions** and display the **validation loss and accuracy** \n",
    "    * Used to **tune your layers** and the **`fit` method’s hyperparameters**, or possibly change the **layer composition** of your model\n",
    "    * Can specify **separate validation data** with **`validation_data` argument** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.6.5 Training and Evaluating the Model (cont.)\n",
    "* Model will take about a minute for every epoch on a standard notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(X_train, y_train, epochs=2, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used later, after the introduction to TensorBoard\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "# import time\n",
    "\n",
    "# tensorboard_callback = TensorBoard(log_dir=f'./logs/mnist{time.time()}', histogram_freq=1, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Used later after the introduction of TensorBoard\n",
    "# cnn.fit(X_train, y_train, epochs=2, batch_size=64, \n",
    "#         validation_split=0.1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.6.5 Training and Evaluating the Model (cont.)\n",
    "* As training proceeds, **`fit`** shows the **progress** of each **epoch**, **how long** the epoch took to execute, and the **evaluation metrics** for that epoch\n",
    "* Impressive **training accuracy (`acc`**) and **validation accurracy (`acc`)**, given that **we have not yet tried to tune the hyperparameters** or **tweak the number and types of the layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model on Unseen Data with Model’s **`evaluate` Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without tuning, our **convnet model** is **99+% accurate** for **unseen data samples**\n",
    "    * Can find models online that predict MNIST with even **higher accuracy**\n",
    "    * **Experiment** with different numbers of layers, types of layers and layer parameters and observe how those changes affect your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with the Model’s **`predict` Method** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first digit should be a 7 (shown as `1.` at index 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the **probabilities** returned by **`predict`** for **first test sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our model believes this digit is a 7 with **nearly** 100% certainty\n",
    "* Not all predictions have this level of certainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating the Incorrect Predictions \n",
    "* View some **incorrectly predicted images** to get a sense of digits **our model has trouble with**\n",
    "\t* If the model always mispredicts 8s, perhaps we need more 8s in our training data\n",
    "* To determine whether a prediction was correct, compare the index of the largest probability in `predictions[0]` to the index of the element containing **`1.0` in `y_test[0]`**\n",
    "\t* If **indices** are the same, **prediction was correct**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating the Incorrect Predictions (cont.)\n",
    "* **Reshape the samples** from the shape `(28, 28, 1)` that Keras required for learning back to `(28, 28)`, which **Matplotlib requires to display the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = X_test.reshape((10000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the following snippet, **`p`** is the **predicted value array**, and **`e`** is the **expected value array**\n",
    "* **NumPy’s `argmax` function** determines **index** of an array’s **highest valued element**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (p, e) in enumerate(zip(predictions, y_test)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "\n",
    "    if predicted != expected:  # prediction was incorrect\n",
    "        incorrect_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(incorrect_predictions)  # number of incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Incorrect Predictions\n",
    "* **Display 24 of the incorrect images** labeled with each image’s index, predicted value (`p`) and expected value (`e`)\n",
    "* Before reading the **expected values**, look at each digit and write down what digit you think it is\n",
    "* This is an important part of **getting to know your data**\n",
    "<!--![24 incorrectly predicted digit images](./ch15images/incorrect24.png \"24 incorrectly predicted digit images\")-->\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=4, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), incorrect_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_xticks([])  # remove x-axis tick marks\n",
    "    axes.set_yticks([])  # remove y-axis tick marks\n",
    "    axes.set_title(f'index: {index}\\np: {predicted}; e: {expected}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Probabilities for Several Incorrect Predictions\n",
    "* The following function displays the probabilities for the specified prediction array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_probabilities(prediction):\n",
    "    for index, probability in enumerate(prediction):\n",
    "        print(f'{index}: {probability:.10%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Note:** We can check the probabilities of correctly and incorrectly classified numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_probabilities(predictions[340])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_probabilities(predictions[1232])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.6.6 Saving and Loading a Model \n",
    "* Can **save state** of a model\n",
    "* Can **load it later** to \n",
    "    * Make more predictions\n",
    "    * Train more\n",
    "    * Train for new problems\n",
    "    * **Transfer learning** to a new model [\\[1\\]](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751), [\\[2\\]](https://medium.com/nanonets/nanonets-how-to-use-deep-learning-when-you-have-limited-data-f68c0b512cab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.6.6 Saving and Loading a Model (cont.)\n",
    "* Can store **model architecture** and **state** in a **Hierarchical Data Format (HDF5)** file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load a saved model \n",
    "\n",
    ">```python\n",
    "from tensorflow.keras.models import load_model\n",
    "cnn = load_model('mnist_cnn.h5')\n",
    "```\n",
    "\n",
    "* Can then invoke its methods\n",
    "    * Could call **`predict`** to make **additional predictions on new data**\n",
    "    * Could call **`fit`** to **train with additional data**\n",
    "* [Additional functions that enable you to **save and load various aspects of your models**](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (16.1): Image Recognition: The Fashion-MNIST Dataset\n",
    "* The Fashion-MNIST dataset (bundled with Keras) is very similar to the MNIST Dataset. Instead of handwritten digits it contains grayscale images of fashion articles (trousers, pullover, dress, coat etc.)\n",
    "* Develop a CNN for classifying the Fashion-MNIST images. It will be very similar to the one we have used in this chapter.\n",
    "* How well does the model perform compared to our MNIST-model? How do the training times compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (16.2 - 16.5): Hyperparameter Tuning\n",
    "* Select one or more of the following exercises to improve the performance of your classification model:\n",
    "    * Exercise 16.2: Changing the Kernel Size\n",
    "    * Exercise 16.3: Changing the Batch Size\n",
    "    * Exercise 16.4: Experiment with Different Dense Layers\n",
    "    * Exercise 16.5: Use Smaler Training Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 16 of the book **Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**.\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
