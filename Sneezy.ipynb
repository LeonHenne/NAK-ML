{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaMoDRR00NWz"
      },
      "source": [
        "# **Sneezy defeating Google Recaptcha**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4poTTNG4FeO"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htm1TnlN37qS"
      },
      "source": [
        "Thema: Eine interessante und lehrreiche Datenanalyse auf einem von Ihnen wählbaren Datenset\n",
        "\n",
        "Einschränkung: Keines der \"klassischen\" Datensets aus scikit-learn oder Keras.\n",
        "Die Arbeit soll Ihre Kompetenzen im Bereich Maschinelles Lernen demonstrieren.\n",
        "Die Arbeit soll die Bereiche \"Domainverständnis\", \"Datenvorverarbeitung\", \"Analyse\" und \"Visualisierung\" abdecken.\n",
        "Sie können sich an anderen Arbeiten orientieren, müssen das Gelernte dann aber auf Ihren gewählten Analysegegenstand übertragen.\n",
        "Verwendete Quellen müssen im Notebook angegeben werden.\n",
        "Format: Ein vollständiges und in sich abgeschlossenes Jupyter Notebook\n",
        "\n",
        "Das vollständig ausgeführte Jupyter Notebook ist zusätzlich auch als PDF-Datei einzureichen.\n",
        "Falls die analysierten Daten zu umfangreich sind um sie mitabzugeben, reicht ein Link auf das Datenset.\n",
        "Gruppengröße: 4 Personen (in Sonderfällen 3 Personen)\n",
        "\n",
        "Bearbeitungszeitraum: **16.08 - 08.09.2023**\n",
        "\n",
        "**23.08: Einreichung einer Projektskizze** (ca. eine DIN A4-Seite): untersuchte Daten, gewählte Fragestellung, geplantes Vorgehen, Aufgabenverteilung in der Gruppe\n",
        "\n",
        "**30.08: Abgabe eines Zwischenstands** (lauffähiges Jupyter Notebook) und eines Zwischenberichts (ca. eine DIN A4-Seite): erreichter Stand, aufgetretene Herausforderungen, begründete Abweichungen von der Projektskizze\n",
        "\n",
        "**08.09: Abgabe der finalen Version (vollständiges Jupyter Notebook + Erklärung)**\n",
        "Erklärung: Unterschriebene Eigenständigkeitserklärung + Aufschlüsselung der Arbeitsaufteilung innerhalb der Gruppe (Hauptverantwortlichkeiten für Bestandteile + individueller Beitrag in Prozent der Gesamtleistung)\n",
        "\n",
        "Arbeitsumfang: 40 - 50 Arbeitsstunden pro Person\n",
        "\n",
        "Bewertungskriterien laut Masterhausarbeitsvorlage:\n",
        "\n",
        "Gliederung der Arbeit / Aufbau und Darstellung der Problemstellung / Systematik / Struktur (\"roter Faden\")\n",
        "Wissenschaftlichkeit / Inhaltliche Vollständigkeit und Richtigkeit / Themenrelevanz / Quellenarbeit / Eigenleistung\n",
        "Klarheit der Darstellung & Stringenz der Argumentationskette / formale Korrektheit / Rechtschreibung / Schreibstil\n",
        "Zielpublikum: Studierende Ihres Studiengangs\n",
        "\n",
        "Fokus: Demonstration Ihrer Kompetenzen + Wissensvermittlung (das konkrete Analyseergebnis ist nachrangig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyVckKxoH0lc"
      },
      "source": [
        "## Projektskizze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr888BT9Hauu"
      },
      "source": [
        "### Google reCAPTCHA V2\n",
        "\n",
        "\n",
        "#### Hintergrund und Kontext\n",
        "\n",
        "[Google reCAPTCHA](https://developers.google.com/recaptcha/docs/display) ist ein Sicherheitswerkzeug, das entwickelt wurde, um zwischen menschlichen Benutzern und Bots zu unterscheiden und so Missbrauch und Cyberangriffe zu verhindern. \n",
        "\n",
        "Die Version, reCAPTCHA V2, stellt Benutzern Herausforderungen wie die Identifizierung von Objekten in Bildern. \n",
        "\n",
        "Das Umgehen dieser Sicherheitsmaßnahme mittels maschinellen Lernens und tiefen neuronalen Netzen ist sowohl technisch als auch wissenschaftlich interessant, da es die Leistungsfähigkeit dieser Modelle testet und gleichzeitig zur Verbesserung der Sicherheit von CAPTCHA-Systemen beitragen kann.\n",
        "\n",
        "#### Fragestellungen und Ziele\n",
        "\n",
        "Zu welcher Genauigkeit können derzeit Modelle mittels Verfahren des maschinellen Lernens optimiert werden, um in der Anwendung Google’s Recaptha V2 Bilder korrekt zu klassifizieren?\n",
        "\n",
        "- Welche Methoden zur Qualitätsverbesserung von Bilddatensätzen (z.B. Resampling, Data Augmentation) werden aktuell in der Forschung bevorzugt, und wie wirken sich diese auf das Training von CNNs aus?\n",
        "\n",
        "- Was sind die neuesten Entwicklungen (State-of-the-Art) in der Bildverarbeitung mit maschinellem Lernen, insbesondere bei der Verwendung von tiefen neuronalen Netzen wie Inceptionv3?  \n",
        "\n",
        "- Welche in der Forschung bestehenden Metriken zur Klassifikation eignen sich zur Lösung des oben beschriebenen Anwendungsfalls?\n",
        "\n",
        "#### Geplantes Vorgehen und Aufgabenverteilung\n",
        "\n",
        "- Explorative Datenanalyse (EDA): Untersuchung der Daten durch Visualisierungen und deskriptive Statistiken, um erste Einblicke zu gewinnen. (Hauptverantwortlich: Rares, Niklas)\n",
        "\n",
        "- Datenvorbereitung: Erstellen eines geeigneten Datensatzes durch Resizing, Resampling und extrahieren von Labels aus der Ordnerstruktur (Paarprogrammierung)\n",
        "\n",
        "- Modellierung: Auswahl und Anwendung geeigneter statistischer Modelle oder Algorithmen zur Beantwortung der Fragestellung. (Hauptverantwortlich: Leon)\n",
        "\n",
        "- Ergebnisse und Interpretation: Analyse der Ergebnisse der Modelle, Interpretation der Befunde und Vergleich mit bestehenden Theorien. (Paarprogrammierung)\n",
        "\n",
        "- Berichterstattung: Erstellung eines detaillierten Berichts, der die Ergebnisse zusammenfasst und Empfehlungen basierend auf den Befunden gibt. (Paarprogrammierung)\n",
        "\n",
        "Das Projekt wird im Google Colab1 entwickelt.\n",
        "\n",
        "#### Literatur und Quellen\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/cry2003/google-recaptcha-v2-images\n",
        "\n",
        "Notebook – InceptionV3: https://www.kaggle.com/code/ahmedhossam666/google-recapthca\n",
        "\n",
        "ResNet Paper: https://arxiv.org/abs/1512.03385\n",
        "\n",
        "Google RecapthaV2: https://developers.google.com/recaptcha/docs/display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu7g25uqWgbY"
      },
      "source": [
        "## 0. Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0_cK93eWj43"
      },
      "outputs": [],
      "source": [
        "\"\"\" This module defines the logging component.\"\"\"\n",
        "\n",
        "import logging\n",
        "\n",
        "\n",
        "def create_logger(log_level: str, logger_name: str = \"custom_logger\"):\n",
        "    \"\"\"Create a logging based on logger.\n",
        "\n",
        "    Args:\n",
        "        log_level (str): Kind of logging\n",
        "        logger_name (str, optional): Name of logger\n",
        "\n",
        "    Returns:\n",
        "        logger: returns logger\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(logger_name)\n",
        "    logger.setLevel(logging.DEBUG)  # Set the base logging level to the lowest (DEBUG)\n",
        "\n",
        "    # If logger already has handlers, don't add a new one\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    # Create a console handler and set the level based on the input\n",
        "    console_handler = logging.StreamHandler()\n",
        "    if log_level == \"DEBUG\":\n",
        "        console_handler.setLevel(logging.DEBUG)\n",
        "    elif log_level == \"INFO\":\n",
        "        console_handler.setLevel(logging.INFO)\n",
        "    elif log_level == \"WARNING\":\n",
        "        console_handler.setLevel(logging.WARNING)\n",
        "    elif log_level == \"ERROR\":\n",
        "        console_handler.setLevel(logging.ERROR)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid log level provided\")\n",
        "\n",
        "    # Create a formatter and set it for the console handler\n",
        "    formatter = logging.Formatter(\n",
        "        \"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        "    console_handler.setFormatter(formatter)\n",
        "\n",
        "    # Add the console handler to the logger\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGt1M53No4P5"
      },
      "outputs": [],
      "source": [
        "logger = create_logger(\n",
        "    log_level=\"INFO\",\n",
        "    logger_name=__name__,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGkiRdzlq5sF"
      },
      "source": [
        "## 1. Laden der Daten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYjKmz9E4_MH"
      },
      "source": [
        "Git für Python installieren und importieren\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWuHhT72vK34"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gitpython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs6wQ0Xrv12z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgvQKAj5vHOw"
      },
      "source": [
        "Google Drive in Google Colab-Notebook einbinden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9th75We80Hqh",
        "outputId": "dc7d41a3-2a3b-4f15-9b17-e619919e54fd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr6oB38u5H8R"
      },
      "source": [
        "Erstelle einen Ordner auf deinem lokalen Laufwerk und navigiere hinein\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWkocNqb1e_O",
        "outputId": "f10b4a48-c104-4dd7-9045-1dc24b971d19"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/MADS2400'\n",
        "if os.path.isdir(file_path):\n",
        "  %cd /content/drive/MyDrive/MADS2400\n",
        "else:\n",
        "  %mkdir /content/drive/MyDrive/MADS2400\n",
        "  %cd /content/drive/MyDrive/MADS2400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 load data locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7CGITG35OBE"
      },
      "source": [
        "Liste alle Dateien in dem Ordner auf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM44ILYy1uo7",
        "outputId": "13e52768-03bd-434e-8298-e8ad27075a30"
      },
      "outputs": [],
      "source": [
        "%ls -a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4XxXy9bFfyg"
      },
      "source": [
        "Durch die Nutzung eines Tokens wird der Datensatz lokal auf dem Google Drive kopiert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngNy8K222mZA",
        "outputId": "ae3215e0-46c1-4556-e803-e293178bcda9"
      },
      "outputs": [],
      "source": [
        "# TODO: refactor this cell so that there is no error occuring\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "if not os.path.isdir('/content/drive/MyDrive/MADS2400/Google-Recaptcha-V2-Images') or not os.path.isdir('Google-Recaptcha-V2-Images'):\n",
        "  git_fine_grained_token = os.environ[\"git_fine_grained_token\"]\n",
        "  username = 'RaresMihai11'\n",
        "  repository = 'Google-Recaptcha-V2-Images'\n",
        "  !git clone https://{git_fine_grained_token}@github.com/{username}/{repository}\n",
        "else:\n",
        "  logger.info(\"already cloned image repository\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY_o0mUp8qag"
      },
      "source": [
        "Liste alle Dateien auf und navigiere in den Ordner Google-Recaptcha-V2-Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e9hvQVf3UJW",
        "outputId": "01f053d5-24d9-4229-cf06-4cb3f5e8f14b"
      },
      "outputs": [],
      "source": [
        "%ls -a\n",
        "%cd Google-Recaptcha-V2-Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYcjKsys86GN"
      },
      "source": [
        "List all the files and navigate into Bicycle folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47cgY7uo5ajC",
        "outputId": "7f7f03b4-a649-4d85-8eb4-f6571079a4df"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2CFg5j0MgXW"
      },
      "source": [
        "## 2. Explorative Datenanalyse\n",
        "\n",
        "#### *Notiz:* <br> Folgend wird angenommen, dass alle Bilder entsprechend ihres Inhalts korrekt den Ordnern einer Klasse zugewiesen wurden. <br> Eine manuelle Überprüfung aller Bilder und ihrer Sortierung ist unter gegebenen Ressourcen dieser Arbeit nicht umsetzbar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ8bzEj_S4Qe"
      },
      "source": [
        "### Verzeichnisstruktur und Dateianzahl\n",
        "Nach dem erfolgreichen Transfer der Daten auf das lokale Laufwerk ist der erste Schritt die Untersuchung der Verzeichnisstruktur und der Dateianzahl. Dies ermöglicht einen Überblick über die Organisation und die Verteilung der Daten innerhalb der verschiedenen Ordner.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzO8kYaARR45",
        "outputId": "1f6ebeba-1833-4e74-9a76-76a2c6ea4051"
      },
      "outputs": [],
      "source": [
        "main_dir = '../Google-Recaptcha-V2-Images/'\n",
        "\n",
        "folders = [\"Bicycle\", \"Bus\", \"Chimney\", \"Hydrant\", \"Mountain\", \"Palm\", \"Stair\",\n",
        "           \"Bridge\", \"Car\", \"Crosswalk\", \"Motorcycle\", \"Other\", \"TLight\"]\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(main_dir, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        num_files = len([f for f in os.listdir(folder_path) if f.endswith('png') or f.endswith('jpg')])\n",
        "        # TODO: dictonary aufbauen (i. e. ['Bicycle'] = 1656)\n",
        "        print(f'{folder}: {num_files} Bilder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HWHQbh1zDRp"
      },
      "source": [
        "### Klassenverteilung\n",
        "Die Anzahl der Bilder in jeder Klasse wurde überprüft und im Balkendiagramm dargestellt. Es ist zu erkennen, dass der Datensatz nicht ausgeglichen ist. Das kann zu einem Bias im Modell führen und die Modellleistung beeinträchtigen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "wqIbhqNFzFpx",
        "outputId": "2bef2c91-7e0b-4457-9e35-dccd46d1bf49"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# class_counts = dict.values()\n",
        "class_counts = {folder: len([f for f in os.listdir(os.path.join(main_dir, folder)) if f.endswith('png') or f.endswith('jpg')]) for folder in folders}\n",
        "\n",
        "# Balkendiagramm der Klassenverteilung\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_counts.keys(), class_counts.values())\n",
        "plt.xlabel('Klassen')\n",
        "plt.ylabel('Anzahl der Bilder')\n",
        "plt.title('Verteilung der Bilder pro Klasse')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d1OTEN_0Kcd"
      },
      "source": [
        "### Dateiendungen prüfen\n",
        "Die Verteilung der Bildformate (z.B. PNG, JPG) wurde untersucht, um sicherzustellen, dass alle Formate berücksichtigt werden. Eine dritte Kategorie für alle anderen Dateiendungen wurde erstellt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "X76dBOn6zvIL",
        "outputId": "4218183b-9f00-49be-fcad-d16455bb4a7d"
      },
      "outputs": [],
      "source": [
        "file_formats = []\n",
        "other_formats = 0\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(main_dir, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_extension = file.split('.')[-1].lower()\n",
        "            if file_extension in ['png', 'jpg', 'jpeg']:\n",
        "                file_formats.append(file_extension)\n",
        "            else:\n",
        "                other_formats += 1\n",
        "\n",
        "# Füge die Anzahl anderer Formate zur Liste hinzu\n",
        "file_formats.extend(['other'] * other_formats)\n",
        "\n",
        "# Balkendiagramm der Bildformate\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(file_formats, bins=len(set(file_formats)), color='blue', edgecolor='black')\n",
        "plt.xlabel('Bildformat')\n",
        "plt.ylabel('Anzahl der Bilder')\n",
        "plt.title('Verteilung der Bildformate')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkFvsNzK2L92"
      },
      "source": [
        "### Bildgrößen und Auflösungen\n",
        "Die Verteilung der Bildbreiten und -höhen wurde visualisiert, um ein besseres Verständnis der Größenverteilung innerhalb des Datensatzes zu erlangen. Diese Information ist entscheidend für die Entscheidung über die Bildskalierung und -normalisierung in späteren Schritten der Datenvorverarbeitung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPx71I6VTJAy"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_sizes = []\n",
        "for folder in folders:\n",
        " folder_path = os.path.join(main_dir, folder)\n",
        " if os.path.isdir(folder_path):\n",
        "  for file in os.listdir(folder_path):\n",
        "      if file.endswith('png') or file.endswith('jpg'):\n",
        "          img_path = os.path.join(folder_path, file)\n",
        "          with Image.open(img_path) as img:\n",
        "           if img.size not in image_sizes:\n",
        "            image_sizes.append(img.size)\n",
        "\n",
        "logger.info(f\"Einzigartige Bildgrößen: {image_sizes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7uBt2TK8_Ls"
      },
      "source": [
        "### Plotte ein Bild aus jedem Ordner\n",
        "Ein visueller Eindruck des Datensatzes wurde durch das Anzeigen von Beispielbildern aus jedem Ordner gewonnen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n76PTAUfHEZO",
        "outputId": "9e68c2bf-4af0-4acb-eeef-d7c27cbecf7e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "main_dir = '../Google-Recaptcha-V2-Images/'\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "\n",
        "count = 0\n",
        "\n",
        "for folder in folders:\n",
        "    if count >= 16:\n",
        "        break\n",
        "    folder_path = os.path.join(main_dir, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        files = os.listdir(folder_path)\n",
        "        img_files = [f for f in files if f.endswith('png') or f.endswith('jpg')]\n",
        "\n",
        "        if img_files:\n",
        "            img_path = os.path.join(folder_path, img_files[1])\n",
        "            img = mpimg.imread(img_path)\n",
        "\n",
        "            row = count // 4\n",
        "            col = count % 4\n",
        "\n",
        "            axes[row, col].imshow(img)\n",
        "            axes[row, col].set_title(folder)\n",
        "            axes[row, col].axis('off')\n",
        "            count += 1\n",
        "\n",
        "\n",
        "for i in range(count, 16):\n",
        "    row = i // 4\n",
        "    col = i % 4\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKD5GyA05FiS"
      },
      "source": [
        "### Zusammenfassung und Schlussfolgerungen der EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUdGaFGR5ILf"
      },
      "source": [
        "**Erkenntnisse**\n",
        "\n",
        "Verteilung der Bildanzahlen: Die meisten Bilder sind in der Kategorie „Car“ vorhanden, was möglicherweise darauf hinweist, dass diese Kategorie am häufigsten vorkommt oder für die reCAPTCHA-Herausforderungen am wichtigsten ist.\n",
        "\n",
        "Kategorien mit wenig Bildern: Kategorien wie „Mountain“ haben nur sehr wenige Bilder, was zu einer Ungleichheit in der Datenmenge führen kann.\n",
        "\n",
        "Mögliche Anomalien: Kategorien wie „Mountain“ könnten als mögliche Anomalien betrachtet werden, die weitere Aufmerksamkeit erfordern.\n",
        "\n",
        "**Empfehlungen**\n",
        "\n",
        "Datenbalance: Eine Datenbalancierung könnte notwendig sein, um sicherzustellen, dass das Modell gleichmäßig über alle Kategorien trainiert wird.\n",
        "\n",
        "Weitere Datensammlung: Für Kategorien mit wenigen Bildern könnten zusätzliche Daten gesammelt werden, um die Modellleistung zu verbessern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZWKkxZ24Y2H"
      },
      "source": [
        "## 3. Erstellen eines maschinellen Datensatzes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWq75h_X4eWK"
      },
      "source": [
        "Das Ziel dieses Abschnitts ist die Erzeugung eines Datensatzes, für die maschinelle Verarbeitung geeignet ist\n",
        "\n",
        "1. Resizing (Veränderung der Bildgröße)\n",
        "2. Resampling (Veränderung der Auflösung)\n",
        "3. Encoding\n",
        "\n",
        "4. Create Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9k74BRrlLev",
        "outputId": "28dbc397-f257-416a-a235-4d127fb937de"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEGyMSF0t2r4",
        "outputId": "ce14f2cb-5d01-4703-e3e0-085abe4bf4d1"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "train, validation = keras.utils.image_dataset_from_directory(\n",
        "    os.getcwd(),\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(120, 120),\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=.2,\n",
        "    subset='both',\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    pad_to_aspect_ratio=False,\n",
        "    data_format='channels_last',\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD-NLn5Wt2h9",
        "outputId": "afb18616-6811-4cb2-89f5-31384e56fac0"
      },
      "outputs": [],
      "source": [
        "logger.info(f\"training dataset contains {len(train)} Batches\")\n",
        "logger.info(f\"testing dataset contains {len(validation)} Batches\")\n",
        "\n",
        "for element in train:\n",
        "  print(f\"shape X_train: {element[0].shape}\")\n",
        "  print(f\"shape Y_train: {element[1].shape}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Manually create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697y_2qBShvD",
        "outputId": "b7ef4921-e67d-4ed2-9d75-8dcedcfaa69d"
      },
      "outputs": [],
      "source": [
        "categories = []\n",
        "\n",
        "# Iterate over the directories in the current main dir\n",
        "for category_dir in os.listdir(os.getcwd()):\n",
        "    # Append the file path to the list\n",
        "    if os.path.isdir(category_dir) and category_dir != '.git':  # Ensure it's a file and not a directory\n",
        "        categories.append(category_dir)\n",
        "\n",
        "print(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz-YllJodQKU",
        "outputId": "58f4f556-536c-4779-aa12-da3fe977b497"
      },
      "outputs": [],
      "source": [
        "files = {}\n",
        "for category in categories:\n",
        "  files[category] = []\n",
        "  for file_path in os.listdir(main_dir + category):\n",
        "    files[category].append(file_path)\n",
        "\n",
        "files[categories[0]][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZjs1_E7aQMI",
        "outputId": "e9475c5d-84ce-4b18-bdff-0be5cb8a296c"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "\n",
        "\n",
        "rgba_image = PIL.Image.open('/content/drive/MyDrive/MADS2400/Google-Recaptcha-V2-Images/Bridge/Bridge$00c8fb02ed155a864575f69c4130359a.png')\n",
        "input_arr = img_to_array(rgba_image)\n",
        "logger.info(input_arr.shape)\n",
        "rgb_image = rgba_image.convert('RGB')\n",
        "input_arr = img_to_array(rgb_image)\n",
        "logger.info(input_arr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "-1SD52HFRyXG",
        "outputId": "0e0e526b-adfe-459c-e595-6bf54e9aacda"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "rgba_image\n",
        "\n",
        "s = []\n",
        "\n",
        "for category in files.keys():\n",
        "  for image in [files[category]][0]:\n",
        "    # Load an image using PIL\n",
        "    path = main_dir + category +'/'+ image\n",
        "\n",
        "    image = load_img(path)\n",
        "    input_arr = img_to_array(image)\n",
        "    # if input_arr.shape[]\n",
        "    # rgba_image = Image.open(path)\n",
        "    # rgb_image = rgba_image.convert('RGB')\n",
        "    if input_arr.shape not in s:\n",
        "      print(input_arr.shape)\n",
        "      s.append(input_arr.shape)\n",
        "\n",
        "  logger.info(f'processed category {category}')\n",
        "#   break\n",
        "# input_arr = np.array(s)\n",
        "# logger.info(f\"s {s}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKCyuqZ6Xqqf",
        "outputId": "05a77603-060b-4c82-f26e-a7ba8792d8fb"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Entwicklung einer neuronalen Netzarchitektur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Überprüfung der GPU Unterstützung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF6n7USdrDME"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow.keras\n",
        "import tensorflow as tf\n",
        "import platform\n",
        "\n",
        "print(f\"Python Platform: {platform.platform()}\")\n",
        "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
        "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
        "print()\n",
        "print(f\"Python {sys.version}\")\n",
        "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
        "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution3D, Dense, Flatten, Dropout, GlobalAvgPool3D\n",
        "resnet50v2 = keras.applications.ResNet50V2(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_shape=(120, 120, 3),\n",
        "    name='resnet50v2')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(resnet50v2)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import time\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir=f'../logs/captcha-{time.time()}',   \n",
        "    histogram_freq=1, write_graph=True)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=f'../models/{time.time()}/'+'model-{epoch:02d}-{val_loss:.2f}.keras',\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose =1)\n",
        "\n",
        "callbacks= [tensorboard_callback,\n",
        "            checkpoint_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "model.compile(optimizer=\"adam\", \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train, epochs=5, validation_data=validation, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c4poTTNG4FeO",
        "lu7g25uqWgbY",
        "hGkiRdzlq5sF",
        "Y7uBt2TK8_Ls"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
